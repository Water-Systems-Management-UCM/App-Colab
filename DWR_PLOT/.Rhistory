geom_point(data = bind_cols(d, b11.11$criteria$loo$diagnostics),
aes(y = total_tools, size = pareto_k),
alpha = 4/5) +
geom_text(data = text,
aes(y = total_tools, label = label),
family = "serif") +
scale_fill_manual(values = wes_palette("Moonrise2")[1:2]) +
scale_color_manual(values = wes_palette("Moonrise2")[1:2]) +
scale_size(range = c(2, 5)) +
scale_x_continuous("population", breaks = c(0, 50000, 150000, 250000)) +
ylab("total tools") +
coord_cartesian(xlim = range(d$population),
ylim = range(d$total_tools)) +
theme(legend.position = "none")
b11.11 <- add_criterion(b11.11, criterion = "loo", moment_match = T)
loo(b11.11)
# for the annotation
text <-
distinct(d, cid) %>%
mutate(population  = c(210000, 72500),
total_tools = c(59, 68),
label       = str_c(cid, " contact"))
# redifine the new data
nd <-
distinct(d, cid) %>%
expand(cid,
population = seq(from = 0, to = 300000, length.out = 100))
# compute the poster predictions for lambda
fitted(b11.11,
newdata = nd,
probs = c(.055, .945)) %>%
data.frame() %>%
bind_cols(nd) %>%
# plot!
ggplot(aes(x = population, group = cid, color = cid)) +
geom_smooth(aes(y = Estimate, ymin = Q5.5, ymax = Q94.5, fill = cid),
stat = "identity",
alpha = 1/4, size = 1/2) +
geom_point(data = bind_cols(d, b11.11$criteria$loo$diagnostics),
aes(y = total_tools, size = pareto_k),
alpha = 4/5) +
geom_text(data = text,
aes(y = total_tools, label = label),
family = "serif") +
scale_fill_manual(values = wes_palette("Moonrise2")[1:2]) +
scale_color_manual(values = wes_palette("Moonrise2")[1:2]) +
scale_size(range = c(2, 5)) +
scale_x_continuous("population", breaks = c(0, 50000, 150000, 250000)) +
ylab("total tools") +
coord_cartesian(xlim = range(d$population),
ylim = range(d$total_tools)) +
theme(legend.position = "none")
loo_compare(b11.10, b11.11, criterion = "loo") %>% print(simplify = F)
model_weights(b11.10, b11.11, weights = "loo") %>% round(digits = 3)
tibble(b11.10 = b11.10$criteria$loo$diagnostics$pareto_k,
b11.11 = b11.11$criteria$loo$diagnostics$pareto_k) %>%
pivot_longer(everything()) %>%
ggplot(aes(x = value, y = name)) +
geom_vline(xintercept = c(.5, .7, 1), linetype = 3, color = wes_palette("Moonrise2")[2]) +
stat_dots(slab_fill = wes_palette("Moonrise2")[1],
slab_color = wes_palette("Moonrise2")[1]) +
scale_x_continuous(expression(Pareto~italic(k)), breaks = c(.5, .7, 1)) +
ylab(NULL) +
coord_cartesian(ylim = c(1.5, 2.4))
set.seed(11)
num_days <- 30
y        <- rpois(num_days, lambda = 1.5)
num_weeks <- 4
y_new     <- rpois(num_weeks, lambda = 0.5 * 7)
(
d <-
tibble(y         = c(y, y_new),
days      = rep(c(1, 7), times = c(num_days, num_weeks)),  # this is the exposure
monastery = rep(0:1, times = c(num_days, num_weeks))) %>%
mutate(log_days = log(days))
)
b11.12 <-
brm(data = d,
family = poisson,
y ~ 1 + offset(log_days) + monastery,
prior = c(prior(normal(0, 1), class = Intercept),
prior(normal(0, 1), class = b)),
iter = 2000, warmup = 1000, cores = 4, chains = 4,
seed = 11,
file = "b11.12")
View(d)
print(b11.12)
posterior_samples(b11.12) %>%
mutate(lambda_old = exp(b_Intercept),
lambda_new = exp(b_Intercept + b_monastery)) %>%
pivot_longer(contains("lambda")) %>%
mutate(name = factor(name, levels = c("lambda_old", "lambda_new"))) %>%
group_by(name) %>%
mean_hdi(value, .width = .89) %>%
mutate_if(is.double, round, digits = 2)
library(rethinking)
# simulate career choices among 500 individuals
n      <- 500           # number of individuals
income <- c(1, 2, 5)    # expected income of each career
score  <- 0.5 * income  # scores for each career, based on income
# next line converts scores to probabilities
p <- softmax(score[1], score[2], score[3])
# now simulate choice
# outcome career holds event type values, not counts
career <- rep(NA, n)  # empty vector of choices for each individual
# sample chosen career for each individual
set.seed(34302)
# sample chosen career for each individual
for(i in 1:n) career[i] <- sample(1:3, size = 1, prob = p)
print(score)
# put them in a tibble
d <-
tibble(career = career) %>%
mutate(career_income = ifelse(career == 3, 5, career))
# plot
d %>%
ggplot(aes(x = career)) +
geom_bar(size = 0, fill = wes_palette("Moonrise2")[2])
d %>%
count(career) %>%
mutate(percent     = (100 * n / sum(n)),
probability =        n / sum(n))
tibble(income = c(1, 2, 5)) %>%
mutate(score = 0.5 * income) %>%
mutate(p = exp(score) / sum(exp(score)))
tibble(income        = c(1, 2, 5),
some_constant = 11) %>%
mutate(score = (0.5 * income) + some_constant) %>%
mutate(p = exp(score) / sum(exp(score)))
# define the model
code_m11.13 <- "
data{
int N; // number of individuals
int K; // number of possible careers
int career[N]; // outcome
vector[K] career_income;
}
parameters{
vector[K - 1] a; // intercepts
real<lower=0> b; // association of income with choice
}
model{
vector[K] p;
vector[K] s;
a ~ normal(0, 1);
b ~ normal(0, 0.5);
s[1] = a[1] + b * career_income[1];
s[2] = a[2] + b * career_income[2];
s[3] = 0; // pivot
p = softmax(s);
career ~ categorical(p);
}
"
# wrangle the data
dat_list <-
list(N = n,
K = 3,
career = career,
career_income = income)
# fit the model
m11.13 <-
stan(data = dat_list,
model_code = code_m11.13,
chains = 4)
post <- extract.samples(m11.13)
post <- extract.samples(m11.13)
# set up logit scores
s1      <- with(post, a[, 1] + b * income[1])
s2_orig <- with(post, a[, 2] + b * income[2])
s2_new  <- with(post, a[, 2] + b * income[2] * 2)
# compute probabilities for original and counterfactual
p_orig <- sapply(1:length(post$b), function(i)
softmax(c(s1[i], s2_orig[i], 0)))
p_new <- sapply(1:length(post$b), function(i)
softmax(c(s1[i], s2_new[i], 0)))
# summarize
p_diff <- p_new[2, ] - p_orig[2, ]
precis(p_diff)
data.frame(s1 = score[3] + s1,
s2 = score[3] + s2_orig,
s3 = score[3] + 0) %>%
pivot_longer(everything()) %>%
group_by(name) %>%
mean_qi(value) %>%
mutate_if(is.double, round, digits = 2)
b11.13io <-
brm(data = d,
family = categorical(link = logit, refcat = 3),
career ~ 1,
prior = c(prior(normal(0, 1), class = Intercept, dpar = mu1),
prior(normal(0, 1), class = Intercept, dpar = mu2)),
iter = 2000, warmup = 1000, cores = 4, chains = 4,
seed = 11,
file = "b11.13io")
update.packages(ask = FALSE)
update.packages(ask = FALSE)
setwd("~/Documents/nass_app/Buffers")
setwd("~/")
setwd("~/Documents/nass_app/Buffers")
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
SHP <- readOGR("matheny.shp", GDAL1_integer64_policy = TRUE)
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
SHP <- raster("matheny.shp")
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
library(raster)
SHP <- shapefile("matheny.shp")
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
SHP <- shapefile('matheny.shp')
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
SHP <- shapefile('matheny.shp',as.sf = TRUE)
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
library(raster)
SHP <- shapefile('matheny.shp',as.sf = TRUE)
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
SHP <- shapefile('matheny.shp')
SHP <- shapefile('matheny.shp')
??shapefile
SHP <- readOGR('matheny.shp')
SHP <- readOGR('matheny.shp',layer = "matheny")
SHP <- readOGR('LandUse2017_Clipped.shp',layer = "LandUse2017_Clipped")
View(SHP)
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
View(SHP)
SHP <- shapefile('LandUse2017_Clipped.shp')
leaflet(SHP) %>%
addProviderTiles("CartoDB.Positron")
SHP <- shapefile('LandUse2017_Clipped.shp')
shapeData <- spTransform(SHP, CRS("+proj=longlat +datum=WGS84 +no_defs"))
leaflet(shapeData) %>%
addProviderTiles("CartoDB.Positron")
SHP <- readOGR('LandUse2017_Clipped.shp',"LandUse2017_Clipped")
shapeData <- spTransform(SHP, CRS("+proj=longlat +datum=WGS84 +no_defs"))
leaflet(shapeData) %>%
addProviderTiles("CartoDB.Positron")
View(SHP)
View(shapeData)
View(SHP)
View(shapeData)
View(SHP)
leaflet() %>%
addProviderTiles("CartoDB.Positron")%>%addPolygons(data=shapeData,weight=5,col = 'red')
View(SHP)
View(SHP)
SHP <- readOGR('matheny.shp',"matheny")
shapeData <- spTransform(SHP, CRS("+proj=longlat +datum=WGS84 +no_defs"))
leaflet() %>%
addProviderTiles("CartoDB.Positron")%>%addPolygons(data=shapeData,weight=5,col = 'red')
SHP <- readOGR('matheny.shp',"matheny")
SHP <- readOGR('matheny.shp',layer="matheny")
SHP <- shapeData('matheny.shp')
shapeData <- spTransform(SHP, CRS("+proj=longlat +datum=WGS84 +no_defs"))
SHP <- shapefile('matheny.shp')
SHP <- readOGR('matheny.shp')
shapeData <- spTransform(SHP, CRS("+proj=longlat +datum=WGS84 +no_defs"))
leaflet() %>%
addProviderTiles("CartoDB.Positron")%>%addPolygons(data=shapeData,weight=5,col = 'red')
View(SHP)
View(SHP)
SHP@data
SHP <- readOGR('400m_SJV.shp')
shapeData <- spTransform(SHP, CRS("+proj=longlat +datum=WGS84 +no_defs"))
leaflet() %>%
addProviderTiles("CartoDB.Positron")%>%addPolygons(data=shapeData,weight=5,col = 'red')
View(shapeData)
shapeData@data
leaflet() %>%
addProviderTiles("CartoDB.Positron")%>%addPolygons(data=shapeData,weight=5,col = 'red')%>%
leaflet::addLegend( values = shapeData$Id,
position = "bottomright",
title = Id),
labFormat = labelFormat(suffix = ""))
popup <- paste0("Buffer: ", shapeData$Id)
leaflet() %>%
addProviderTiles("CartoDB.Positron")%>%addPolygons(data=shapeData,weight=5,col = 'red',popup = popup)
runApp('~/Documents/nass_app/DWR_PLOT/app_PLOT.R')
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(Total_Land=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land)
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land),`Total water`=sum(TW))%>%ungroup()
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na()%>%select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2019 as base year
Inflation <-  inflation_adjust(base_year=2019)
Inflation_1 <- Inflation%>%select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Total Production Value`=`Value category`*(1+(1-adj_value))/1000,`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
Data <- melt(as.data.frame(CSV_data),id=c("NAME","Crop","Year"))
Data <- Data%>%filter(variable!="AW")
Data[Data$variable%in%c("Total water","Total land"),]$Crop = "Sum All"
Data <- Data %>% unique(by=c("NAME","Year","Crop","variable","value"))
Data$variable <- as.character(Data$variable)
Data[Data$variable=="AW2",]$variable = "Applied water per acre"
Data[Data$variable=="Total_Land",]$variable = "Land use"
Data[Data$variable=="TW",]$variable = "Water use"
Data[Data$variable=="Total water",]$variable = "Water use"
Data[Data$variable=="Total land",]$variable = "Land use"
Data$Year <- as.numeric(Data$Year)
###################################################
Unique_Crops <- unique(sort(Data$Crop))
Unique_Years <- unique(sort(Data$Year,decreasing=TRUE))
Unique_Vars <- unique(Data$variable)
Unique_County <- unique(Data$NAME)
n <- 23
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
labels <-c("Acre-feet/acre" = "Applied water per acre","Thousand acres"="Land use","Thousand \n acre-feet"="Water use","USD/Acre-feet","USD/acre-foot"="Gross revenue per acre-foot")
ui <- fluidPage(
# App title ----
titlePanel("Water and Land Use"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
selectInput(inputId="CropChosen", label="Crop Category", choices=Unique_Crops, selected = "Almonds & Pistachios", multiple = FALSE),
selectInput(inputId="CountyChosen", label="County", choices=Unique_County, selected = c("Fresno","Kern"), multiple = TRUE),
selectInput(inputId="variable", label="Variable", choices=Unique_Vars, selected = "Land use", multiple = FALSE),
sliderInput(inputId = "YearsChosen",
label = "Year Range",
min = 1998,
max = 2015,
value = c(1998,2015),
step = 1,round=TRUE,sep = ""),
# Button
downloadButton("downloadtable","Download"),
downloadButton("downloadData2","Download All Data")
),
# Main panel for displaying outputs ----
mainPanel(
girafeOutput("plot1")   )
))
server <- shinyServer(function(input, output){
output$plot1 <- renderGirafe({
data1 <-  Data %>% filter(Crop %in% input$CropChosen & NAME %in% input$CountyChosen & Year >= min(input$YearsChosen) & Year <=max(input$YearsChosen)& variable == input$variable)
plot <- ggplot(data1, aes(x=Year, y= value, colour=NAME)) + geom_line(alpha=1,size=1.5,aes(colour=NAME))+ geom_point_interactive(aes(x=Year, y=value,colour=NAME,tooltip=paste(glue("County: {NAME}\nYear: {Year}\nVariable: {variable}\nValue:{value}")),data_id=value),size=2) + scale_colour_manual(values= col_vector)+theme_minimal()+labs(title= paste(as.character(input$variable),"\n ","Crop Category:",as.character(input$CropChosen)),y= names(labels[which(labels == input$variable)]), caption = "Data source: DWR Land and Water use estimates \nMonetary values were adjusted to 2019 using consumer price index\nReported gross revenue are from the crop with the largest area\n in each crop category, year and county using NASS data set\nDeveloped by Water Systems Management Lab UC Merced")+theme(
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5),
plot.caption = element_text(hjust= 0),panel.border = element_rect(colour = "black", fill=NA, size=0.5),plot.caption.position =  "plot")
girafe(ggobj = plot,
options = list(opts_selection(type = "single"),code=print(plot), opts_tooltip(
opacity = 0.8, use_fill = TRUE,
use_stroke = FALSE,
css = "padding:5pt;font-family:Times;color:black"),
opts_hover_inv(css = "opacity:0.8"),
opts_hover(css = "fill:#4c6061;")))
})
#download output table
output$downloadtable <- downloadHandler(
filename = function() {
paste('Output','.csv', sep='')
},
content = function(file) {
data1 <-  Data %>% filter(Group_name %in% input$CropChosen & County %in% input$CountyChosen & Year >= min(input$YearsChosen) & Year <=max(input$YearsChosen))
write.csv(data1, file)
}
)
output$downloadData2 <- downloadHandler(
filename = function() {
"All_data_dwr.csv"
},
content = function(file) {
write.csv(CSV_data,file,row.names = FALSE)
}
)
})
shinyApp(ui = ui, server = server)
names <- read_csv("names.csv")
setwd("~/Documents/nass_app/DWR_PLOT")
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
runApp('app_PLOT.R')
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(Total_Land=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land)
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land),`Total water`=sum(TW))%>%ungroup()
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na()%>%select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2019 as base year
Inflation <-  inflation_adjust(base_year=2019)
Inflation_1 <- Inflation%>%select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Total Production Value`=`Value category`*(1+(1-adj_value))/1000,`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na()%>%select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
roup_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na()%>%select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
View(names)
runApp('app_PLOT.R')
View(names)
