mutate(lambda_old = exp(b_Intercept),
lambda_new = exp(b_Intercept + b_monastery)) %>%
pivot_longer(contains("lambda")) %>%
mutate(name = factor(name, levels = c("lambda_old", "lambda_new"))) %>%
group_by(name) %>%
mean_hdi(value, .width = .89) %>%
mutate_if(is.double, round, digits = 2)
library(rethinking)
# simulate career choices among 500 individuals
n      <- 500           # number of individuals
income <- c(1, 2, 5)    # expected income of each career
score  <- 0.5 * income  # scores for each career, based on income
# next line converts scores to probabilities
p <- softmax(score[1], score[2], score[3])
# now simulate choice
# outcome career holds event type values, not counts
career <- rep(NA, n)  # empty vector of choices for each individual
# sample chosen career for each individual
set.seed(34302)
# sample chosen career for each individual
for(i in 1:n) career[i] <- sample(1:3, size = 1, prob = p)
print(score)
# put them in a tibble
d <-
tibble(career = career) %>%
mutate(career_income = ifelse(career == 3, 5, career))
# plot
d %>%
ggplot(aes(x = career)) +
geom_bar(size = 0, fill = wes_palette("Moonrise2")[2])
d %>%
count(career) %>%
mutate(percent     = (100 * n / sum(n)),
probability =        n / sum(n))
tibble(income = c(1, 2, 5)) %>%
mutate(score = 0.5 * income) %>%
mutate(p = exp(score) / sum(exp(score)))
tibble(income        = c(1, 2, 5),
some_constant = 11) %>%
mutate(score = (0.5 * income) + some_constant) %>%
mutate(p = exp(score) / sum(exp(score)))
# define the model
code_m11.13 <- "
data{
int N; // number of individuals
int K; // number of possible careers
int career[N]; // outcome
vector[K] career_income;
}
parameters{
vector[K - 1] a; // intercepts
real<lower=0> b; // association of income with choice
}
model{
vector[K] p;
vector[K] s;
a ~ normal(0, 1);
b ~ normal(0, 0.5);
s[1] = a[1] + b * career_income[1];
s[2] = a[2] + b * career_income[2];
s[3] = 0; // pivot
p = softmax(s);
career ~ categorical(p);
}
"
# wrangle the data
dat_list <-
list(N = n,
K = 3,
career = career,
career_income = income)
# fit the model
m11.13 <-
stan(data = dat_list,
model_code = code_m11.13,
chains = 4)
post <- extract.samples(m11.13)
post <- extract.samples(m11.13)
# set up logit scores
s1      <- with(post, a[, 1] + b * income[1])
s2_orig <- with(post, a[, 2] + b * income[2])
s2_new  <- with(post, a[, 2] + b * income[2] * 2)
# compute probabilities for original and counterfactual
p_orig <- sapply(1:length(post$b), function(i)
softmax(c(s1[i], s2_orig[i], 0)))
p_new <- sapply(1:length(post$b), function(i)
softmax(c(s1[i], s2_new[i], 0)))
# summarize
p_diff <- p_new[2, ] - p_orig[2, ]
precis(p_diff)
data.frame(s1 = score[3] + s1,
s2 = score[3] + s2_orig,
s3 = score[3] + 0) %>%
pivot_longer(everything()) %>%
group_by(name) %>%
mean_qi(value) %>%
mutate_if(is.double, round, digits = 2)
b11.13io <-
brm(data = d,
family = categorical(link = logit, refcat = 3),
career ~ 1,
prior = c(prior(normal(0, 1), class = Intercept, dpar = mu1),
prior(normal(0, 1), class = Intercept, dpar = mu2)),
iter = 2000, warmup = 1000, cores = 4, chains = 4,
seed = 11,
file = "b11.13io")
update.packages(ask = FALSE)
update.packages(ask = FALSE)
setwd("~/Documents/nass_app/DWR_APP")
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
library(RColorBrewer)
library(dplyr)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%mutate(AW=dplyr::na_if(AW,0),Total_Land=dplyr::na_if(Total_Land,0),TW=dplyr::na_if(TW,0))
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(max=max(Total_Land))%>%mutate(Total_Land1=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land1)%>%mutate(proxy=ifelse(Total_Land==max,1,0))%>%filter(proxy==1)%>%ungroup()
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land1),`Total water`=sum(TW))%>%ungroup()%>%dplyr::select(-c("proxy","max","Total_Land"))
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
View(CSV_data)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
View(CSV_data)
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%mutate(AW=dplyr::na_if(AW,0),Total_Land=dplyr::na_if(Total_Land,0),TW=dplyr::na_if(TW,0))
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(max=max(Total_Land))%>%mutate(Total_Land1=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land1)%>%mutate(proxy=ifelse(Total_Land==max,1,0))%>%filter(proxy==1)%>%ungroup()
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land1),`Total water`=sum(TW))%>%ungroup()%>%dplyr::select(-c("proxy","max","Total_Land"))
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
View(dgroup_data)
View(CSV_data)
runApp('app2.R')
runApp('app2.R')
runApp('app2.R')
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
library(RColorBrewer)
library(dplyr)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%mutate(AW=dplyr::na_if(AW,0),Total_Land=dplyr::na_if(Total_Land,0),TW=dplyr::na_if(TW,0))
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(max=max(Total_Land))%>%mutate(Total_Land1=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land1)%>%mutate(proxy=ifelse(Total_Land==max,1,0))%>%filter(proxy==1)%>%ungroup()
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land1),`Total water`=sum(TW))%>%ungroup()%>%dplyr::select(-c("proxy","max","Total_Land"))
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
CSV_data <- CSV_data%>%mutate("Adjusted Total Production Value" = `Adjusted Gross Revenue`*Total_land1)
View(CSV_data)
runApp('app2.R')
CSV_data <- CSV_data%>%group_by("NAME","Year")%>%mutate("Adjusted Production Value1" = sum(`Adjusted Total Production Value`,na.rm=TRUE))
View(CSV_data)
CSV_data <- CSV_data%>%mutate("Adjusted Total Production Value" = `Adjusted Gross Revenue`*Total_Land1)
CSV_data <- CSV_data%>%group_by("NAME","Year")%>%mutate("Adjusted Production Value1" = sum(`Adjusted Total Production Value`,na.rm=TRUE))
Data <- Data%>%filter(variable!="AW")
Data <- melt(as.data.frame(CSV_data),id=c("NAME","Crop","Year"))
Data[Data$variable%in%c("Total water","Total land","Adjusted Total Production Value1"),]$Crop = "Sum All"
Data$variable <- as.character(Data$variable)
Data[Data$variable=="Total_Land1",]$variable = "Land use"
Data[Data$variable=="Total water",]$variable = "Water use"
Data[Data$variable=="Adjusted Total Production Value1",]$variable = "Adjusted Total Production Value"
runApp('app2.R')
View(CSV_data)
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
library(RColorBrewer)
library(dplyr)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%mutate(AW=dplyr::na_if(AW,0),Total_Land=dplyr::na_if(Total_Land,0),TW=dplyr::na_if(TW,0))
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(max=max(Total_Land))%>%mutate(Total_Land1=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land1)%>%mutate(proxy=ifelse(Total_Land==max,1,0))%>%filter(proxy==1)%>%ungroup()
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land1),`Total water`=sum(TW))%>%ungroup()%>%dplyr::select(-c("proxy","max","Total_Land"))
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
CSV_data <- CSV_data%>%mutate("Adjusted Total Production Value" = `Adjusted Gross Revenue`*Total_Land1)
CSV_data <- CSV_data%>%group_by("NAME","Year")%>%mutate("Adjusted Total Production Value1" = sum(`Adjusted Total Production Value`,na.rm=TRUE))
View(CSV_data)
View(proxy)
View(CSV_data)
View(proxy)
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
library(RColorBrewer)
library(dplyr)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%mutate(AW=dplyr::na_if(AW,0),Total_Land=dplyr::na_if(Total_Land,0),TW=dplyr::na_if(TW,0))
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(max=max(Total_Land))%>%mutate(Total_Land1=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land1)%>%mutate(proxy=ifelse(Total_Land==max,1,0))%>%filter(proxy==1)%>%ungroup()
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land1),`Total water`=sum(TW))%>%ungroup()%>%dplyr::select(-c("proxy","max","Total_Land"))
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
CSV_data1 <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
View(CSV_data1)
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
CSV_data <- CSV_data%>%mutate("Adjusted Total Production Value" = `Adjusted Gross Revenue`*Total_Land1)
CSV_data <- CSV_data%>%group_by("NAME","Year")%>%mutate("Adjusted Total Production Value1" = sum(`Adjusted Total Production Value`,na.rm=TRUE))
View(CSV_data)
library('shiny')
library('leaflet')
library('shiny')
library('ggplot2')
library('plyr')
library(dplyr)
library(tigris) #download shp file from U.S. census website
library(rgdal)
library(tmap)
library(tidyverse)
library(tmaptools)
library(reshape)
library(rvest)
library(quantmod)
library(DT)
library(blscrapeR)
library(RColorBrewer)
library(dplyr)
names <- read_csv("names.csv")
CSV_data <- read.csv("AW.DWRdata.csv")
CSV_data <- CSV_data%>%mutate(AW=dplyr::na_if(AW,0),Total_Land=dplyr::na_if(Total_Land,0),TW=dplyr::na_if(TW,0))
CSV_data <- CSV_data%>%group_by(NAME,Year,Crop)%>%mutate(max=max(Total_Land))%>%mutate(Total_Land1=sum(Total_Land)/1000,TW=sum(TW)/1000)%>%mutate(AW2=TW/Total_Land1)%>%mutate(proxy=ifelse(Total_Land==max,1,0))%>%filter(proxy==1)%>%ungroup()
CSV_data <- CSV_data%>%group_by(NAME,Year)%>%mutate(`Total land`=sum(Total_Land1),`Total water`=sum(TW))%>%ungroup()%>%dplyr::select(-c("proxy","max","Total_Land"))
###################################################
#Bring NASS
#All years data
link <- "https://www.nass.usda.gov"
list_links <- read_html("https://www.nass.usda.gov/Statistics_by_State/California/Publications/AgComm/index.php") %>% html_nodes("a") %>% html_attr("href")
list_links <- grep(".csv",list_links,value=TRUE)
colnames <- c('Year','Commodity Code','Crop','County Code','County','Acres','Yield','Production','Price','Unit','Value')
list_links <- list_links[-3]
all_data <- lapply(list_links, function(i) read_csv(paste(link,i,sep=""),col_names = FALSE))%>%bind_rows()%>%set_names(colnames)%>%filter(!grepl("Year|year",Year))
all_data$County[all_data$County=="San Luis Obisp"]="San Luis Obispo"
all_data <- all_data%>%filter(!County%in%c("Sum of Others","State Totals","State Total"))
#Put group names
group_data <- all_data%>%left_join(names,by="Commodity Code")%>%drop_na(`Commodity Code`)%>%dplyr::select(Year,"Commodity Code",County,Acres,Yield,Price,`Crop Name`,Group_name,Value,`County Code`)
group_data$Acres <-  as.numeric(group_data$Acres)
group_data$Price <-  as.numeric(group_data$Price)
group_data$Yield <-  as.numeric(group_data$Yield)
group_data$Value <-  as.numeric(group_data$Value)
#Find proxy
dgroup_data <- group_data%>%group_by(Group_name,Year,`County Code`)%>%mutate(`Total Area` = sum(Acres)/1000,`Value category`=sum(Value))%>%ungroup()
dgroup_data2 <-  dgroup_data%>%group_by(`Commodity Code`,`County Code`,Year)%>%mutate(Rate = Acres/`Total Area`)%>%ungroup()
dgroup_data2 <- dgroup_data2%>%group_by(`County Code`,Group_name,Year)%>%mutate(max=max(Rate),`Gross revenue`=Price*Yield)%>%mutate(proxy=ifelse(Rate==max,1,0))%>%filter(proxy==1)%>%ungroup()
#Adjust for inflation
# Price inflation data using 2020 as base year
Inflation <-  inflation_adjust(base_year=2020)
Inflation_1 <- Inflation%>%dplyr::select(year,adj_value)%>%dplyr::rename(Year=year)
#look at the table
#Column adj value is the % of 2019 dollars in each year if we want to bring x value from any year to 2019 then x(2019) = x(any year)*(1+(1-adj_value))
proxy <- dgroup_data2 %>%left_join(Inflation_1,by="Year")
proxy <- proxy%>%mutate(`Adjusted Price`=Price*(1+(1-adj_value)),`Adjusted Gross Revenue`=`Gross revenue`*(1+(1-adj_value)))%>%dplyr::rename(NAME=County,Crop=Group_name)
proxy$Year <- as.numeric(proxy$Year)
proxy <- proxy%>%dplyr::select(Year,Crop,NAME,`Adjusted Gross Revenue`)
###################################################
CSV_data <- CSV_data%>%left_join(proxy,by=c("NAME","Crop","Year"))
CSV_data <- CSV_data%>%mutate("Gross revenue per acre-foot" = `Adjusted Gross Revenue`/AW2)
CSV_data <- CSV_data%>%mutate("Adjusted Total Production Value" = `Adjusted Gross Revenue`*Total_Land1)
View(CSV_data)
CSV_data1 <- CSV_data%>%group_by("NAME","Year")%>%mutate("Adjusted Total Production Value1" = sum(`Adjusted Total Production Value`,na.rm=TRUE))
runApp('app2.R')
View(CSV_data)
View(proxy)
View(dgroup_data2)
session
runApp('~/Documents/nass_app/DWR_PLOT/app_PLOT.R')
runApp('~/Documents/nass_app/DWR_PLOT/app_PLOT.R')
runApp('~/Documents/nass_app/DWR_PLOT/app_PLOT.R')
runApp('~/Documents/nass_app/DWR_PLOT/app_PLOT.R')
